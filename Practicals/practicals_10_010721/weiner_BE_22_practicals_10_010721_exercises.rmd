---
title: "Practicals 10: Machine learning"
subtitle: "BE_22 Bioinformatics SS 21"
author: "January Weiner"
date: "`r Sys.Date()`"
output:
    html_document:
      toc: true
      toc_float: true
outputxxx:
  xaringan::moon_reader:
    self-contained: true
    css: ["default", "files/cubi-fonts.css", "files/style.css" ]
    lib_dir: libs
    nature:
      highlightStyle: github
      countIncrementalSlides: false
      ratio: "16:9"
      beforeInit: "files/macros.js"
toc: no
---

```{r,echo=FALSE}
## Set default options for the knitr RMD processing
knitr::opts_chunk$set(echo=TRUE,warning=FALSE,message=FALSE,fig.width=7,fig.height=5,cache=TRUE,autodep=TRUE, results="hide")
options(crayon.enabled = TRUE)
options(crayon.colors = 256)
knitr::knit_hooks$set(output = function(x, options){
  paste0(
    '<pre class="r-output"><code>',
    fansi::sgr_to_html(x = htmltools::htmlEscape(x), warn = FALSE),
    '</code></pre>'
  )
})

## this is an ugly, ugly hack, but otherwise crayon does not LISTEN TO REASON!!!
num_colors <- function(forget=TRUE) 256
library(crayon)
assignInNamespace("num_colors", num_colors, pos="package:crayon")
```

```{r libraries,cache=FALSE,echo=FALSE}
library(ggplot2)
library(tidyverse)
library(DESeq2)
library(tmod)
library(edgeR)
theme_set(theme_bw())
options(colorDF_n=30)
options(width=100)
```

# Prerequisites

Please install the following packages:

```{r eval=FALSE}
install.packages(c("randomForest", "party", "rpart", "MASS"))
```

# Machine learning algorithms

There are numerous machine learning algorithms:

 * decision trees
   * with bagging
   * with boosting
   * random forests
 * support vector machines (SVMs)
 * projections to latent structures (PLS)
 * linear discriminant analysis
 * regression models (e.g. logistic regression, ridge regression, lasso
   regression, elastic nets)
 * neuronal networks
 * deep learning algorithms

Today, we will first apply LDA to the iris data set, and then we will apply
decision trees to a metabolome data set.

# Iris data set

## Creating a training and test set

```{r}
data(iris)
n <- nrow(iris) # 150
train <- sample(1:n, size=2/3 * n)
test  <- setdiff(1:n, train)

iris_train <- iris[train, ]
iris_test  <- iris[test,  ]
```

**Exercise. (5 min)** Make sure that you understand *exactly* what is happening
above. Ask questions if necessary. How many samples are in the training
set? How many in the test set? How many of each species is in the test set?
Are the group sizes balanced? (what does "balanced" mean?)

## LDA with the iris data set

First, we create a model for discriminating between versicolor and
virginica iris species only. 

```{r}
data(iris)
library(MASS)
library(tidyverse)
iris_train_vv <- iris_train %>% filter(Species != "setosa") %>%
  mutate(Species=factor(Species))
mod_lda_vv <- lda(Species ~ ., data=iris_train_vv)
```

The result is an object of class `lda`, which is a list. The element
`scaling` (`mod_lda_vv$scaling`) contains a matrix with the coefficients
for each of the four features (variables). We now can calculate the values
of the LD function for each of the samples. We use here the `predict`
function, but we are not predicting anything â€“ this is still the training
set.

```{r}
iris_train_vv_pred <- predict(mod_lda_vv, iris_train_vv)
iris_train_vv_pred <- iris_train_vv_pred$x[,1]
```

The element `x` of the object returned by `predict` is a matrix with one column containing the LD values. We can visualize
the data with a boxplot:

```{r}
df <- data.frame(Species=iris_train_vv$Species, LD=iris_train_vv_pred)
ggplot(df, aes(x=Species, y=LD)) + geom_boxplot()
```

We see that LD is high for *virginica* and low for *versicolor*.

**Exercise (5min)**. The coefficients for Sepals in the LD are negative,
while the coefficients for Petals are positive. LD is positive for *virginica*
and negative for *versicolor*. Question: based on this fact, are petals
larger in *virginica* or in *versicolor*?

## Making and testing predictions

We can now make predictions for the test set:

```{r}
iris_test_vv <- iris_test %>% filter(Species != "setosa") %>%
  mutate(Species=factor(Species))
iris_test_vv_pred <- predict(mod_lda_vv, iris_test_vv)
iris_test_vv_pred <- iris_test_vv_pred$x[,1]
df <- cbind(iris_test_vv, LD=iris_test_vv_pred)
ggplot(df, aes(x=Species, y=LD)) + geom_boxplot()
```

A natural cutoff seems to be for $LD = 0$. We now will confront the
predictions with reality.

```{r}
pred <- ifelse(iris_test_vv_pred > 0, "virginica", "versicolor")
table(pred, iris_test_vv$Species)
```

**Question.** What is the overall error rate?

**Homework 6**. Repeat the above analysis with the full iris data set
(three classes). You will find that the `scaling` object has now two
columns, `LD1` and `LD2`. Make boxplots for both of them. Which LD
discriminates between which species?


# The metabo data set

The metabo data set contains metabolomic profiles for patients suffering
from tuberculosis (TB) and of two classes of healthy controls: LTBI, that is
individuals who are healthy, but infected with *Mycobacterium tuberculosis*, and CTRL,
who are healthy and uninfected.

```{r data_prep,eval=FALSE,echo=FALSE}
library(readxl)
f <- "/home/january/MPIB-01-08CO ClientDataTable.xls"
s <- "ScaledSparsedImpData"
dat <- read_excel(f, sheet = s, range="I13:EP401", col_names = FALSE,
                  col_types = "numeric") %>% data.matrix()
coldat <- read_excel(f, sheet = s, range="H1:EP10", col_names = FALSE,
                  col_types = "text") %>% t() %>% data.frame()
colnames(coldat) <- coldat[1,]
coldat <- coldat[-1, ]
coldat <- coldat %>% mutate(SAMPLE_NAME=gsub("-", "_", SAMPLE_NAME)) %>%
  select(SAMPLE_NAME, GENDER, GROUP1) %>%
  mutate(GROUP1=ifelse(GROUP1 == "A_TST_NEG", "CTRL",
                       ifelse(GROUP1 == "B_TST_POS", "LTBI", "TB")))
colnames(dat) <- coldat[["SAMPLE_NAME"]]

fdat <- read_excel(f, sheet = s, range="A12:G401", col_names = TRUE,
                  col_types = "text") %>% 
        mutate(ID=paste0("ID_", 1:n())) %>% relocate(ID)
rownames(dat) <- fdat$ID
vars <- apply(dat, 1, var)
sel <- vars > quantile(vars, .1)

fdat <- fdat[sel, ]
dat  <-  dat[sel, ]

```



